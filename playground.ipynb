{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5898074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def update_path(source_path, new_path_prefix):\n",
    "    filename = source_path.split('/')[-1]\n",
    "    return new_path_prefix + filename\n",
    "\n",
    "driving_log = pd.read_csv('data/driving_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d764327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_in = len(driving_log)\n",
    "X_train = np.zeros((6*num_in, 160, 320, 3), dtype=np.uint8)\n",
    "y_train = np.zeros(6*num_in, dtype=float)\n",
    "\n",
    "high_steering = (driving_log.steering < -0.25) | (driving_log.steering > 0.25)\n",
    "\n",
    "for i, (img_path_orig, steering_angle) in enumerate(zip(driving_log['center'], driving_log['steering'])):\n",
    "    img_path = update_path(img_path_orig, 'data/IMG/')\n",
    "    image = plt.imread(img_path)\n",
    "    X_train[2*i] = image\n",
    "    y_train[2*i] = steering_angle\n",
    "    X_train[2*i+1] = np.fliplr(image)\n",
    "    y_train[2*i+1] = -steering_angle\n",
    "    \n",
    "for i, (img_path_orig, steering_angle) in enumerate(zip(driving_log['left'], driving_log['steering'])):\n",
    "    img_path = update_path(img_path_orig, 'data/IMG/')\n",
    "    image = plt.imread(img_path)\n",
    "    steering_angle += 0.25\n",
    "    X_train[2*num_in + 2*i] = image\n",
    "    y_train[2*num_in + 2*i] = steering_angle\n",
    "    X_train[2*num_in + 2*i+1] = np.fliplr(image)\n",
    "    y_train[2*num_in + 2*i+1] = -steering_angle\n",
    "    \n",
    "for i, (img_path_orig, steering_angle) in enumerate(zip(driving_log['right'], driving_log['steering'])):\n",
    "    img_path = update_path(img_path_orig, 'data/IMG/')\n",
    "    image = plt.imread(img_path)\n",
    "    steering_angle -= 0.25\n",
    "    X_train[4*num_in + 2*i] = image\n",
    "    y_train[4*num_in + 2*i] = steering_angle\n",
    "    X_train[4*num_in + 2*i+1] = np.fliplr(image)\n",
    "    y_train[4*num_in + 2*i+1] = -steering_angle\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55741b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38572 samples, validate on 9644 samples\n",
      "Epoch 1/30\n",
      "38572/38572 [==============================] - 85s 2ms/step - loss: 0.0234 - val_loss: 0.0117\n",
      "Epoch 2/30\n",
      "38572/38572 [==============================] - 79s 2ms/step - loss: 0.0070 - val_loss: 0.0124\n",
      "Epoch 3/30\n",
      "38572/38572 [==============================] - 79s 2ms/step - loss: 0.0059 - val_loss: 0.0125\n",
      "Epoch 4/30\n",
      "38572/38572 [==============================] - 79s 2ms/step - loss: 0.0053 - val_loss: 0.0115\n",
      "Epoch 5/30\n",
      "38572/38572 [==============================] - 79s 2ms/step - loss: 0.0050 - val_loss: 0.0105\n",
      "Epoch 6/30\n",
      "38572/38572 [==============================] - 79s 2ms/step - loss: 0.0047 - val_loss: 0.0108\n",
      "Epoch 7/30\n",
      "38572/38572 [==============================] - 80s 2ms/step - loss: 0.0046 - val_loss: 0.0103\n",
      "Epoch 8/30\n",
      "38572/38572 [==============================] - 80s 2ms/step - loss: 0.0044 - val_loss: 0.0108\n",
      "Epoch 9/30\n",
      "38572/38572 [==============================] - 79s 2ms/step - loss: 0.0044 - val_loss: 0.0108\n",
      "Epoch 10/30\n",
      "38572/38572 [==============================] - 80s 2ms/step - loss: 0.0043 - val_loss: 0.0112\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Input, Cropping2D, Dropout, Activation, Concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications import VGG19, VGG16, InceptionV3, ResNet50\n",
    "\n",
    "dropout_rate = 0.3\n",
    "crop_top = 60\n",
    "crop_bottom = 20\n",
    "split_left_right = 140\n",
    "stopper = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3)\n",
    "\n",
    "def my_loss_fn(y_true, y_pred):\n",
    "    weighted_squared_difference = (y_true - y_pred)**2 * (np.abs(y_true) + 0.01) # what if true = 0?\n",
    "    return weighted_squared_difference\n",
    "\n",
    "pretrained = VGG16(weights='imagenet', include_top=False,\n",
    "                   input_shape=(160-crop_top-crop_bottom, 320-split_left_right, 3))\n",
    "for layer in pretrained.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# pretrained_cut = Sequential()  # https://github.com/tensorflow/tensorflow/issues/22479\n",
    "# for layer in pretrained.layers[:-4]:\n",
    "#     pretrained_cut.add(layer)\n",
    "\n",
    "\n",
    "common_dense_layer = Dense(128)\n",
    "\n",
    "def sidewise_block(input_tensor):\n",
    "    x = Lambda(lambda x: (x / 255.0) - 0.5)(input_tensor)\n",
    "    x = pretrained(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    x = common_dense_layer(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "inp = Input(shape=(160,320,3))\n",
    "left = Cropping2D(cropping=((crop_top,crop_bottom), (0,split_left_right)))(inp)\n",
    "right = Cropping2D(cropping=((crop_top,crop_bottom), (split_left_right,0)))(inp)\n",
    "left = sidewise_block(left)\n",
    "right = sidewise_block(right)\n",
    "x = Concatenate(axis=1)([left, right])\n",
    "x = Dropout(rate=dropout_rate)(x)\n",
    "x = Dense(128)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(rate=dropout_rate)(x)\n",
    "out = Dense(1)(x)\n",
    "model = Model(inputs = inp, outputs=out)\n",
    "\n",
    "# inp = Input(shape=(160,320,3))\n",
    "# x = Cropping2D(cropping=((60,20), (0,0)))(inp)\n",
    "# x = Lambda(lambda x: (x / 255.0) - 0.5)(x)\n",
    "# x = pretrained(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dropout(rate=0.3)(x)\n",
    "# x = Dense(400)(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(rate=0.3)(x)\n",
    "# x = Dense(1)(x)\n",
    "# model = Model(inputs = inp, outputs=x)\n",
    "\n",
    "model.compile(loss=my_loss_fn, optimizer='adam')\n",
    "history_object = model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=30,\n",
    "                           batch_size=256, callbacks=[stopper])\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.save('model_h.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1cadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train on 38572 samples, validate on 9644 samples\n",
    "Epoch 1/30\n",
    "38572/38572 [==============================] - 73s 2ms/step - loss: 1293.8032 - val_loss: 0.2095\n",
    "Epoch 2/30\n",
    "38572/38572 [==============================] - 67s 2ms/step - loss: 0.5559 - val_loss: 0.0405\n",
    "Epoch 3/30\n",
    "38572/38572 [==============================] - 67s 2ms/step - loss: 0.0506 - val_loss: 0.0373\n",
    "Epoch 4/30\n",
    "38572/38572 [==============================] - 67s 2ms/step - loss: 0.0307 - val_loss: 0.0367\n",
    "Epoch 5/30\n",
    "38572/38572 [==============================] - 67s 2ms/step - loss: 0.0253 - val_loss: 0.0366\n",
    "Epoch 6/30\n",
    "38572/38572 [==============================] - 67s 2ms/step - loss: 0.0213 - val_loss: 0.0364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c65775bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.save('model_30_custom_loss.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "240617f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv2D at 0x7f8425433c88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained.layers.pop()\n",
    "pretrained.layers.pop()\n",
    "pretrained.layers.pop()\n",
    "pretrained.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a7785e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 160, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_11 (Cropping2D)      (None, 80, 180, 3)   0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_12 (Cropping2D)      (None, 80, 180, 3)   0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 80, 180, 3)   0           cropping2d_11[0][0]              \n",
      "                                                                 cropping2d_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   (None, 2, 5, 512)    7635264     lambda_6[0][0]                   \n",
      "                                                                 lambda_6[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 5120)         0           vgg16[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 5120)         0           vgg16[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 5120)         0           flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 5120)         0           flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          655488      dropout_21[0][0]                 \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 256)          0           dense_16[0][0]                   \n",
      "                                                                 dense_16[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 256)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 256)          0           activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          32896       dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 128)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 128)          0           activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            129         dropout_24[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 8,323,777\n",
      "Trainable params: 688,513\n",
      "Non-trainable params: 7,635,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30b527b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv2D at 0x7f84242fa860>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e6d70ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 80, 180, 3)        0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 80, 180, 64)       1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 80, 180, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 40, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 40, 90, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 40, 90, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 20, 45, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 20, 45, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 20, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 20, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 10, 22, 256)       0         \n",
      "=================================================================\n",
      "Total params: 1,735,488\n",
      "Trainable params: 1,735,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29934fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = VGG16(weights='imagenet', include_top=False,\n",
    "                   input_shape=(160-crop_top-crop_bottom, 320-split_left_right, 3))\n",
    "pre = Sequential()\n",
    "for layer in pretrained.layers[:-8]: # just exclude last layer from copying\n",
    "    pre.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7b63f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 80, 180, 64)       1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 80, 180, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 40, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 40, 90, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 40, 90, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 20, 45, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 20, 45, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 20, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 20, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 10, 22, 256)       0         \n",
      "=================================================================\n",
      "Total params: 1,735,488\n",
      "Trainable params: 1,735,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fab71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.save('test_p.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9b4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
